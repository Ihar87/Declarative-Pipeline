### global properties

### !!! Uncomment needed properties with one # and set values

## command to check hostname
## for AWS please use: curl http://169.254.169.254/latest/meta-data/public-hostname
HOSTNAME_CHECK = curl http://169.254.169.254/latest/meta-data/public-hostname

### Artifactory section

### Common
##Artifactory Type: ftp/nexus/local/s3
ARTIFACT_STORAGE = s3
## AS URL, e.g. http://server_name
ARTIFACTORY_URL = s3://eeuk-upgr-artifactory

### End of AS section

NOHUP = true

## AWS S3 Settings
## !!! Important !!! Please put your AWS access key and secret key into credentials storage with ID=AWS_CREDENTIALS
## and Username=AWS as access key, Password=AWS as secret key
## S3 region code, e.g. us-east-2
S3_REGION = eu-west-1
## S3 bucket name, e.g. s3-test-bucket
S3_BUCKET = eeuk-upgr-artifactory

### Hybris archive information. It will be used to install (unzip) clean hybris for tests.
## Directory where file is located
SOURCE_DIR = /tmp
## If Hybris archive is located on S3 AWS, mark following var as "true" and check correctness of S3 Region and Bucket paths above:
HYBRIS_S3 = true
## File name
SOURCE_FILE = HYBRISCOMM6600P_3-70003031.zip
## For S3, path to source file
HYBRIS_S3_SOURCEDIR = static/hybris
## URL to http with hybris installations. all file shoul have md5 checksum with name {zipfilename}.md5, e.g. hybris6.2.zip.md5
HYBRIS_SOURCES_URL = 

#Bitbucket properties
BITBUCKET_URL = https://bitbucket.intdigital.ee.co.uk
BITBUCKET_PROJECT = shop
BITBUCKET_REPOSITORY = shop

# PR Pipeline properties
SLAVE_NODE_LABEL = ci_slaves
ENVIRONMENT = pr_tests
TEMPLATE = develop

# Feature Verification props
FV_ENVIRONMENT = fv_tests
DEPLOY_NODE_LABEL = fv_slaves
SITE_URLS = "/hac\n/backoffice"

### Jira integration
### Jira plugin should be installed in Jenkins
### Authentication and URL should be configured in Jenkins Global configuration
## This will put comments about Merge or Pull Requests in Jira Ticket
## Git comment should be started with Jira ticket id
JIRA_ENABLE = false
## Jira project code. Used to determine ticket with ID <JIRA_PROJECT_CODE>-1234.
JIRA_PROJECT_CODE = DEL
## Jira URL - will be used in release notes creation
JIRA_URL = https://jira.intdigital.ee.co.uk
## Jira user and password should be added to jenkins credentials with jirauser id

### DB usage
## DB type usage
## if empty - HSQL
## could be mysql, oracle, hsql
DB_TYPE = mysql

### Jenkins properties
## Log Parser rules file location (for Log Parser plugin)
LOG_PARSER_RULES = /opt/jenkins/log_parser_rules
## User which will be used for deploy for multinode envs
DEPLOY_USER = 

### Release notes
## Confluence URL
RN_CONFLUENCE_URL = https://wiki.intdigital.ee.co.uk
## Confluence project code
RN_PROJECT_SPACE_KEY = DIGITAL
## Confluence credentials stored in jenkins
RN_JENKINS_CONF_CREDS_ID = jirauser
## Environment SHA files folder - there are files like env.sha with current git commit sha. Need for Release notes creation.
GIT_COMMIT_FOLDER = /opt/env_sha
## Jira Server name ID - needed in confluence jira plugin
RN_CONF_SERVER_NAME = 

## Hybris ROOT location
HYBRIS_ROOT = /opt/hybris
## Custom ant dir location
CUSTOM_ANT_SCRIPT_DIR = /opt/hybris/hybris/bin/custom/buildscripts/resources/buildscripts/ant


### EMAIL NOTIFICATIONS
## QA group
EMAIL_QA_GROUP = ProjectEEUK-UPGR@epam.com
## DEV group
EMAIL_DEV_GROUP = ProjectEEUK-UPGR@epam.com
## PROJECT group
EMAIL_PROJECT_GROUP = ProjectEEUK-UPGR@epam.com
## DEVOPS group
EMAIL_DEVOPS_GROUP = ProjectEEUK-UPGR@epam.com

### DUMP creation parameters
## Dump artifact storage type: nexus/http/local/s3
DUMP_ARTIFACT_STORAGE = <s3>
## User to connect to http storage type by ssh
DUMP_ARTIFACT_USER = <hybris>
## Artifact storage server name used for dump storing
DUMP_SERVER_NAME = <ServerName>
## Folder name to copy the dump to
DUMP_ROOT_FOLDER = </opt/artifactory/dumps>
## Dump artifactory URL to download dump files
DUMP_ARTIFACTORY_URL = <http://ServerName/dumps>
## Medias storage type: s3/local
MEDIAS_STORAGE_TYPE = <local>
## Folder where dumps are stored on DB server
DB_DUMP_FOLDER = /opt/dump_dir

###Buildkit settings
## Buildkit url
BUILDKIT_URL = 
## buildkit folder on remote server
BUILDKIT_FOLDER = 

### Deployment settings
## Method using to create DB for FV environment: init|update
FV_DB_PREPARATION = init
## FV timeout value for QA stage
FV_QA_TIMEOUT_VALUE = 3
## FV timeout unit for QA stage. Possible values: MINUTES, HOURS, DAYS
FV_QA_TIMEOUT_UNIT = DAYS
## FV timeout value for QA stage
FV_DEV_TIMEOUT_VALUE = 3
## FV timeout unit for QA stage. Possible values: MINUTES, HOURS, DAYS
FV_DEV_TIMEOUT_UNIT = DAYS
## FV timeout value for QA stage
FV_QA_REJECTED_TIMEOUT_VALUE = 4
## FV timeout unit for QA stage. Possible values: MINUTES, HOURS, DAYS
FV_QA_REJECTED_TIMEOUT_UNIT = HOURS

### Solr settings
##Jenkins credential ID for solr backup artifactory
SOLR_BACKUP_SSHAGENT_ID = sshagent
## Solr user (user which owns solr folder)
SOLR_USER = solr
## User on solr server with sudo rights
SOLR_ROOT_USER = hybris
## server name where solr backups are stored
SOLR_BACKUP_SERVER = <ServerName>
## Folder name to copy the solr backups to
SOLR_BACKUP_ROOT_FOLDER = /opt/artifactory/solr_backup
## Solr backup artifactory URL to download backup files
SOLR_BACKUP_ARTIFACTORY_URL = <http://ServerName/solr_backup>
## Solr backup artifact storage type: nexus/http/local
SOLR_BACKUP_ARTIFACT_STORAGE = http
## User to connect to http storage type by ssh
SOLR_BACKUP_ARTIFACT_USER = hybris
## Solr versioned collections to backup or restore
SOLR_VERSIONED_BACKUPS = 
## There will be matching between collection name and ID in job parameter (key name should be started with SOLR_ + collection name)
SOLR_master_radr_collection_default = 

## There will be matching between collection name and local.properties key contains the ID of the collection to restore (key name should be started with SOLR_ID_ + collection name)
SOLR_ID_master_radr_collection_default = <radr.backup.version.id>

